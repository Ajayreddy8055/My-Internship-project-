{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD6mK0y1Mbfa/JRqGAte+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajayreddy8055/My-Internship-project-/blob/main/Natural_Language_Understanding_for_Dialog_Systems_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fGkxvAW0cnxC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import spacy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Acquisition\n",
        "\n",
        "training_data = [\n",
        "    (\"I want to book a flight to New York\", \"book_flight\"),\n",
        "    (\"What is the weather in London tomorrow?\", \"check_weather\"),\n",
        "    (\"Show me laptops under $1000\", \"inquire_product\"),\n",
        "\n",
        "]\n",
        "\n",
        "#  dataset for evaluation\n",
        "evaluation_data = [\n",
        "    (\"I want to book a flight to New York\", {\"intent\": \"book_flight\", \"entities\": {\"destination\": \"New York\"}}),\n",
        "    (\"What is the weather in London tomorrow?\", {\"intent\": \"check_weather\", \"entities\": {\"location\": \"London\", \"date\": \"tomorrow\"}}),\n",
        "    (\"Show me laptops under $1000\", {\"intent\": \"inquire_product\", \"entities\": {\"max_price\": \"$1000\"}}),\n",
        "    # Add more evaluation examples as needed\n",
        "]\n",
        "\n",
        "# Intent Recognition\n",
        "\n",
        "conversation_state = {}\n",
        "\n",
        "\n",
        "responses = {\n",
        "    \"book_flight\": \"Sure! I can help you book a flight to {}.\",\n",
        "    \"check_weather\": \"The weather in {} tomorrow will be {}.\",\n",
        "    \"inquire_product\": \"Here are some laptops under {}: {}.\"\n",
        "}\n",
        "\n",
        "# Function to preprocess text data (e.g., lowercase, remove punctuation)\n",
        "def preprocess_text(text):\n",
        "\n",
        "    return text.lower()\n",
        "\n",
        "# Function to fine-tune BERT model on the training dataset\n",
        "def fine_tune_bert(training_data):\n",
        "\n",
        "    pass\n",
        "\n",
        "# Function to augment training data using data augmentation techniques\n",
        "def augment_data(training_data):\n",
        "\n",
        "    pass\n",
        "\n",
        "# Function to select the best model architecture and hyperparameters\n",
        "def select_model(training_data):\n",
        "\n",
        "    pass\n",
        "\n",
        "# Function to analyze errors made by the model on evaluation data\n",
        "def error_analysis(model, evaluation_data):\n",
        "\n",
        "    pass\n",
        "\n",
        "# Fine-tune BERT model\n",
        "fine_tune_bert(training_data)\n",
        "\n",
        "# Augment training data\n",
        "augmented_training_data = augment_data(training_data)\n",
        "\n",
        "# Select the best model architecture and hyperparameters\n",
        "best_model = select_model(augmented_training_data)\n",
        "\n",
        "# Error analysis\n",
        "error_analysis(best_model, evaluation_data)\n",
        "\n",
        "# Extract intent labels from training data\n",
        "intent_labels = [intent for _, intent in training_data]\n",
        "\n",
        "# Perform label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(intent_labels)\n",
        "encoded_labels = label_encoder.transform(intent_labels)\n",
        "\n",
        "# Convert encoded labels into a tensor\n",
        "label_ids = torch.tensor(encoded_labels)\n",
        "\n",
        "# Entity Extraction\n",
        "\n",
        "def fill_slots(intent, entities):\n",
        "    if intent == \"book_flight\":\n",
        "        conversation_state['destination'] = entities.get('destination', None)\n",
        "    elif intent == \"check_weather\":\n",
        "        conversation_state['location'] = entities.get('location', None)\n",
        "        conversation_state['weather'] = entities.get('weather', None)\n",
        "    elif intent == \"inquire_product\":\n",
        "        conversation_state['max_price'] = entities.get('max_price', None)\n",
        "\n",
        "# Slot Filling and Context Handling\n",
        "\n",
        "def generate_response(intent, entities):\n",
        "    if intent == \"book_flight\":\n",
        "        return responses[intent].format(entities.get('destination', ''))\n",
        "    elif intent == \"check_weather\":\n",
        "        return responses[intent].format(entities.get('location', ''), entities.get('weather', 'unknown'))\n",
        "    elif intent == \"inquire_product\":\n",
        "        return responses[intent].format(entities.get('max_price', ''), \"Dell XPS, HP Spectre, MacBook Pro\")  # Dummy product list\n",
        "\n",
        "# Dialog Management\n",
        "\n",
        "def dialog_manager(user_input):\n",
        "\n",
        "    return \"This is a placeholder response from the bot.\"\n",
        "\n",
        "\n",
        "def simulate_dialog_scenario():\n",
        "    for text, data in evaluation_data:\n",
        "        response = dialog_manager(text)\n",
        "        print(\"User:\", text)\n",
        "        print(\"ChatBot:\", response)\n",
        "\n",
        "# Model Evaluation\n",
        "\n",
        "def evaluate_intent_model():\n",
        "\n",
        "    intent_true = [data[\"intent\"] for _, data in evaluation_data]\n",
        "\n",
        "\n",
        "    intent_pred = []\n",
        "    for text, _ in evaluation_data:\n",
        "        intent_pred.append(predict_intent(text))\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(intent_true, intent_pred)\n",
        "    precision = precision_score(intent_true, intent_pred, average='weighted')\n",
        "    recall = recall_score(intent_true, intent_pred, average='weighted')\n",
        "    f1 = f1_score(intent_true, intent_pred, average='weighted')\n",
        "\n",
        "\n",
        "    print(\"Intent Recognition Evaluation:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "\n",
        "# Function to predict intent using the trained model\n",
        "def predict_intent(text):\n",
        "\n",
        "    return \"book_flight\"\n",
        "\n",
        "# Iterative Improvement\n",
        "\n",
        "def iterative_improvement():\n",
        "\n",
        "    pass\n",
        "\n",
        "# Intent Recognition\n",
        "# Extract features using TF-IDF for intent recognition\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform([text for text, intent in training_data])\n",
        "\n",
        "\n",
        "intent_classifier = LogisticRegression()\n",
        "intent_classifier.fit(X_train, encoded_labels)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(intent_labels)))\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "tokenized_inputs = tokenizer([text for text, _ in training_data], padding=True, truncation=True, return_tensors='pt')\n",
        "model.train()\n",
        "outputs = model(**tokenized_inputs, labels=label_ids.unsqueeze(0))\n",
        "\n",
        "# Evaluate intent recognition model\n",
        "evaluate_intent_model()\n",
        "\n",
        "# Test the complete NLU module in a simulated dialog scenario\n",
        "simulate_dialog_scenario()\n",
        "\n",
        "# Call the function for iterative improvement\n",
        "iterative_improvement()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF01W33jdjHT",
        "outputId": "8954484b-c560-412f-de5f-c8eb20559a1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent Recognition Evaluation:\n",
            "Accuracy: 0.3333333333333333\n",
            "Precision: 0.1111111111111111\n",
            "Recall: 0.3333333333333333\n",
            "F1 Score: 0.16666666666666666\n",
            "User: I want to book a flight to New York\n",
            "ChatBot: This is a placeholder response from the bot.\n",
            "User: What is the weather in London tomorrow?\n",
            "ChatBot: This is a placeholder response from the bot.\n",
            "User: Show me laptops under $1000\n",
            "ChatBot: This is a placeholder response from the bot.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQ1Dw3tLeH72"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQMf2lX6ecct"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAbDUhuGegkw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7JiAhHK7emO2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fu_k9rABer5k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hqiSvt3sevsi"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}